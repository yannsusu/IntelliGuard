{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T13:11:57.476075Z",
     "start_time": "2025-04-09T13:11:50.977402Z"
    }
   },
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ynee/Documents/NUS/venv3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.models.bert.modeling_bert because of the following error (look up to see its traceback):\nmodule 'torch' has no attribute 'compiler'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "File \u001B[0;32m~/Documents/NUS/venv3.11/lib/python3.11/site-packages/transformers/utils/import_utils.py:1976\u001B[0m, in \u001B[0;36m_LazyModule._get_module\u001B[0;34m(self, module_name)\u001B[0m\n\u001B[1;32m   1975\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1976\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mimportlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimport_module\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m.\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mmodule_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;18;43m__name__\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1977\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126\u001B[0m, in \u001B[0;36mimport_module\u001B[0;34m(name, package)\u001B[0m\n\u001B[1;32m    125\u001B[0m         level \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m--> 126\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_bootstrap\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_gcd_import\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m[\u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpackage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1206\u001B[0m, in \u001B[0;36m_gcd_import\u001B[0;34m(name, package, level)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1178\u001B[0m, in \u001B[0;36m_find_and_load\u001B[0;34m(name, import_)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1149\u001B[0m, in \u001B[0;36m_find_and_load_unlocked\u001B[0;34m(name, import_)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:690\u001B[0m, in \u001B[0;36m_load_unlocked\u001B[0;34m(spec)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap_external>:940\u001B[0m, in \u001B[0;36mexec_module\u001B[0;34m(self, module)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:241\u001B[0m, in \u001B[0;36m_call_with_frames_removed\u001B[0;34m(f, *args, **kwds)\u001B[0m\n",
      "File \u001B[0;32m~/Documents/NUS/venv3.11/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:47\u001B[0m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodeling_outputs\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     37\u001B[0m     BaseModelOutputWithPastAndCrossAttentions,\n\u001B[1;32m     38\u001B[0m     BaseModelOutputWithPoolingAndCrossAttentions,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     45\u001B[0m     TokenClassifierOutput,\n\u001B[1;32m     46\u001B[0m )\n\u001B[0;32m---> 47\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodeling_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m PreTrainedModel\n\u001B[1;32m     48\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpytorch_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m apply_chunking_to_forward, find_pruneable_heads_and_indices, prune_linear_layer\n",
      "File \u001B[0;32m~/Documents/NUS/venv3.11/lib/python3.11/site-packages/transformers/modeling_utils.py:55\u001B[0m\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mintegrations\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mflash_attention\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m flash_attention_forward\n\u001B[0;32m---> 55\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mintegrations\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mflex_attention\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m flex_attention_forward\n\u001B[1;32m     56\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mintegrations\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msdpa_attention\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m sdpa_attention_forward\n",
      "File \u001B[0;32m~/Documents/NUS/venv3.11/lib/python3.11/site-packages/transformers/integrations/flex_attention.py:46\u001B[0m\n\u001B[1;32m     41\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mattention\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mflex_attention\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     42\u001B[0m         create_block_mask \u001B[38;5;28;01mas\u001B[39;00m create_block_causal_mask_flex,\n\u001B[1;32m     43\u001B[0m     )\n\u001B[0;32m---> 46\u001B[0m \u001B[38;5;28;43;01mclass\u001B[39;49;00m\u001B[38;5;250;43m \u001B[39;49m\u001B[38;5;21;43;01mWrappedFlexAttention\u001B[39;49;00m\u001B[43m:\u001B[49m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;250;43m    \u001B[39;49m\u001B[38;5;124;43;03m\"\"\"\u001B[39;49;00m\n\u001B[1;32m     48\u001B[0m \u001B[38;5;124;43;03m    We are doing a singleton class so that flex attention is compiled once when it's first called.\u001B[39;49;00m\n\u001B[1;32m     49\u001B[0m \u001B[38;5;124;43;03m    \"\"\"\u001B[39;49;00m\n",
      "File \u001B[0;32m~/Documents/NUS/venv3.11/lib/python3.11/site-packages/transformers/integrations/flex_attention.py:61\u001B[0m, in \u001B[0;36mWrappedFlexAttention\u001B[0;34m()\u001B[0m\n\u001B[1;32m     59\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_instance\n\u001B[0;32m---> 61\u001B[0m \u001B[38;5;129m@torch\u001B[39m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompiler\u001B[49m\u001B[38;5;241m.\u001B[39mdisable(recursive\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m     63\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;124;03m    Initialize or update the singleton instance.\u001B[39;00m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'torch' has no attribute 'compiler'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtransformers\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m BertForSequenceClassification, BertTokenizer\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1231\u001B[0m, in \u001B[0;36m_handle_fromlist\u001B[0;34m(module, fromlist, import_, recursive)\u001B[0m\n",
      "File \u001B[0;32m~/Documents/NUS/venv3.11/lib/python3.11/site-packages/transformers/utils/import_utils.py:1965\u001B[0m, in \u001B[0;36m_LazyModule.__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   1963\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_class_to_module\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[1;32m   1964\u001B[0m     module \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_module(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_class_to_module[name])\n\u001B[0;32m-> 1965\u001B[0m     value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mmodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1966\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_modules:\n\u001B[1;32m   1967\u001B[0m     value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_module(name)\n",
      "File \u001B[0;32m~/Documents/NUS/venv3.11/lib/python3.11/site-packages/transformers/utils/import_utils.py:1964\u001B[0m, in \u001B[0;36m_LazyModule.__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   1962\u001B[0m     value \u001B[38;5;241m=\u001B[39m Placeholder\n\u001B[1;32m   1963\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_class_to_module\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[0;32m-> 1964\u001B[0m     module \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_module\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_class_to_module\u001B[49m\u001B[43m[\u001B[49m\u001B[43mname\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1965\u001B[0m     value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(module, name)\n\u001B[1;32m   1966\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_modules:\n",
      "File \u001B[0;32m~/Documents/NUS/venv3.11/lib/python3.11/site-packages/transformers/utils/import_utils.py:1978\u001B[0m, in \u001B[0;36m_LazyModule._get_module\u001B[0;34m(self, module_name)\u001B[0m\n\u001B[1;32m   1976\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m importlib\u001B[38;5;241m.\u001B[39mimport_module(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m module_name, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)\n\u001B[1;32m   1977\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m-> 1978\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m   1979\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFailed to import \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodule_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m because of the following error (look up to see its\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1980\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m traceback):\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1981\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01me\u001B[39;00m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Failed to import transformers.models.bert.modeling_bert because of the following error (look up to see its traceback):\nmodule 'torch' has no attribute 'compiler'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['classifier.weight', 'classifier.bias'], unexpected_keys=[])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",num_labels=3)\n",
    "state_dict=torch.load('bert_rumor_detection.pth')\n",
    "\n",
    "state_dict = {k: v for k, v in state_dict.items() if 'classifier' not in k}\n",
    "\n",
    "model.load_state_dict(state_dict,strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    task_type=\"SEQ_CLS\", \n",
    "    r=16,  # rank\n",
    "    lora_alpha=32, \n",
    "    lora_dropout=0.1, \n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import json\n",
    "\n",
    "class MyRumorDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=512):\n",
    "        self.texts=texts\n",
    "        self.labels=labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts.iloc[idx])\n",
    "        label = int(self.labels.iloc[idx])\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\",\n",
    "            return_attention_mask=True\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "      <th>policies</th>\n",
       "      <th>entities_in_policy</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P001</td>\n",
       "      <td>The Texas Heartbeat Act prohibits abortions af...</td>\n",
       "      <td>[[Texas Heartbeat Act, LAW], [six weeks, TIME]]</td>\n",
       "      <td>A physician may not knowingly perform or induc...</td>\n",
       "      <td>[[fetal heartbeat, MEDICAL]]</td>\n",
       "      <td>truth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P002</td>\n",
       "      <td>SB8 allows anyone to sue anyone who 'aids or a...</td>\n",
       "      <td>[[SB8, LAW], [$10,000, MONEY]]</td>\n",
       "      <td>If a claimant prevails in an action brought un...</td>\n",
       "      <td>[[$10,000, MONEY]]</td>\n",
       "      <td>truth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P003</td>\n",
       "      <td>Under the Texas Heartbeat Act, the state's att...</td>\n",
       "      <td>[[Texas Heartbeat Act, LAW], [attorney general...</td>\n",
       "      <td>Notwithstanding Section 171.005 or any other l...</td>\n",
       "      <td>[[private civil actions, LEGAL]]</td>\n",
       "      <td>truth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P004</td>\n",
       "      <td>The law defines pregnancy as beginning at fert...</td>\n",
       "      <td>[[fertilization, MEDICAL], [implantation, MEDI...</td>\n",
       "      <td>'Pregnancy' means the human female reproductiv...</td>\n",
       "      <td>[[fertilization, MEDICAL]]</td>\n",
       "      <td>truth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P005</td>\n",
       "      <td>Texas will imprison doctors who perform aborti...</td>\n",
       "      <td>[[doctors, PROFESSION], [imprison, LEGAL]]</td>\n",
       "      <td>Any person, other than an officer or employee ...</td>\n",
       "      <td>[[civil action, LEGAL]]</td>\n",
       "      <td>rumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P006</td>\n",
       "      <td>Physicians are required to document if an abor...</td>\n",
       "      <td>[[medical emergency, MEDICAL], [document, ACTI...</td>\n",
       "      <td>If an abortion is performed or induced on a pr...</td>\n",
       "      <td>[[medical emergency, MEDICAL], [written docume...</td>\n",
       "      <td>truth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>P007</td>\n",
       "      <td>Women who have abortions can be sued and fined...</td>\n",
       "      <td>[[women, DEMOGRAPHIC], [sued, LEGAL], [fined, ...</td>\n",
       "      <td>This subchapter may not be construed to: (1) a...</td>\n",
       "      <td>[[woman, DEMOGRAPHIC], [cause of action, LEGAL]]</td>\n",
       "      <td>rumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>P008</td>\n",
       "      <td>Texas SB8 allows a rapist to sue a doctor who ...</td>\n",
       "      <td>[[rapist, CRIMINAL], [victim, PERSON]]</td>\n",
       "      <td>Notwithstanding any other law, a civil action ...</td>\n",
       "      <td>[[rape, CRIMINAL], [sexual assault, CRIMINAL],...</td>\n",
       "      <td>rumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>P009</td>\n",
       "      <td>A provision within SB8 states that ignorance o...</td>\n",
       "      <td>[[ignorance of the law, LEGAL], [defense, LEGAL]]</td>\n",
       "      <td>Notwithstanding any other law, the following a...</td>\n",
       "      <td>[[ignorance, CONCEPT], [mistake of law, LEGAL]]</td>\n",
       "      <td>truth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>P010</td>\n",
       "      <td>The Texas Heartbeat Act prohibits enforcement ...</td>\n",
       "      <td>[[state officials, PERSON], [federal courts, O...</td>\n",
       "      <td>Notwithstanding Section 171.005 or any other l...</td>\n",
       "      <td>[[private civil actions, LEGAL]]</td>\n",
       "      <td>unverified</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                               text  \\\n",
       "0  P001  The Texas Heartbeat Act prohibits abortions af...   \n",
       "1  P002  SB8 allows anyone to sue anyone who 'aids or a...   \n",
       "2  P003  Under the Texas Heartbeat Act, the state's att...   \n",
       "3  P004  The law defines pregnancy as beginning at fert...   \n",
       "4  P005  Texas will imprison doctors who perform aborti...   \n",
       "5  P006  Physicians are required to document if an abor...   \n",
       "6  P007  Women who have abortions can be sued and fined...   \n",
       "7  P008  Texas SB8 allows a rapist to sue a doctor who ...   \n",
       "8  P009  A provision within SB8 states that ignorance o...   \n",
       "9  P010  The Texas Heartbeat Act prohibits enforcement ...   \n",
       "\n",
       "                                            entities  \\\n",
       "0    [[Texas Heartbeat Act, LAW], [six weeks, TIME]]   \n",
       "1                     [[SB8, LAW], [$10,000, MONEY]]   \n",
       "2  [[Texas Heartbeat Act, LAW], [attorney general...   \n",
       "3  [[fertilization, MEDICAL], [implantation, MEDI...   \n",
       "4         [[doctors, PROFESSION], [imprison, LEGAL]]   \n",
       "5  [[medical emergency, MEDICAL], [document, ACTI...   \n",
       "6  [[women, DEMOGRAPHIC], [sued, LEGAL], [fined, ...   \n",
       "7             [[rapist, CRIMINAL], [victim, PERSON]]   \n",
       "8  [[ignorance of the law, LEGAL], [defense, LEGAL]]   \n",
       "9  [[state officials, PERSON], [federal courts, O...   \n",
       "\n",
       "                                            policies  \\\n",
       "0  A physician may not knowingly perform or induc...   \n",
       "1  If a claimant prevails in an action brought un...   \n",
       "2  Notwithstanding Section 171.005 or any other l...   \n",
       "3  'Pregnancy' means the human female reproductiv...   \n",
       "4  Any person, other than an officer or employee ...   \n",
       "5  If an abortion is performed or induced on a pr...   \n",
       "6  This subchapter may not be construed to: (1) a...   \n",
       "7  Notwithstanding any other law, a civil action ...   \n",
       "8  Notwithstanding any other law, the following a...   \n",
       "9  Notwithstanding Section 171.005 or any other l...   \n",
       "\n",
       "                                  entities_in_policy       label  \n",
       "0                       [[fetal heartbeat, MEDICAL]]       truth  \n",
       "1                                 [[$10,000, MONEY]]       truth  \n",
       "2                   [[private civil actions, LEGAL]]       truth  \n",
       "3                         [[fertilization, MEDICAL]]       truth  \n",
       "4                            [[civil action, LEGAL]]       rumor  \n",
       "5  [[medical emergency, MEDICAL], [written docume...       truth  \n",
       "6   [[woman, DEMOGRAPHIC], [cause of action, LEGAL]]       rumor  \n",
       "7  [[rape, CRIMINAL], [sexual assault, CRIMINAL],...       rumor  \n",
       "8    [[ignorance, CONCEPT], [mistake of law, LEGAL]]       truth  \n",
       "9                   [[private civil actions, LEGAL]]  unverified  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "with open('matched_data.jsonl', 'r', encoding='utf-8') as f:\n",
    "    data = []\n",
    "    for line in f:\n",
    "        line = line.strip()  # Remove any leading/trailing spaces\n",
    "        if line:  # Ensure it's not an empty line\n",
    "            try:\n",
    "                data.append(json.loads(line))\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error parsing line: {line}\")\n",
    "                print(f\"Error message: {e}\")\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Split 'policies' into two columns: 'policy_text' and 'entities'\n",
    "df['entities_in_policy'] = df['policies'].apply(lambda x: x[0]['entities'] if isinstance(x, list) and len(x) > 0 else None)\n",
    "df['policies'] = df['policies'].apply(lambda x: x[0]['policy_text'] if isinstance(x, list) and len(x) > 0 else None)\n",
    "columns = [col for col in df.columns if col != 'label']  # All columns except 'label'\n",
    "columns.append('label')  # Append 'label' as the last column\n",
    "df = df[columns]\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['label'].map({'truth': 0, 'rumor': 1, 'unverified':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting a bar chart for visual analysis\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df['label'].value_counts().plot(kind='bar')\n",
    "plt.title(\"Dataset Class Distribution\")\n",
    "plt.ylabel(\"Number of Instances\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, val_df = train_test_split(\n",
    "    df, \n",
    "    test_size=0.2, \n",
    "    stratify=df['label'], \n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "# train_text=train_df['text'].tolist()\n",
    "# train_label=train_df['label'].tolist()\n",
    "\n",
    "train_dataset = MyRumorDataset(\n",
    "    texts=train_df['text'],\n",
    "    labels=train_df['label'],\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# val_text=val_df['text'].tolist()\n",
    "# val_label=val_df['label'].tolist()\n",
    "\n",
    "val_dataset = MyRumorDataset(\n",
    "    texts=val_df['text'],\n",
    "    labels=val_df['label'],\n",
    "    tokenizer=tokenizer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            preds.extend(predictions.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Compute metrics\n",
    "    acc = accuracy_score(true_labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, preds, average='macro')  # or 'macro' if multi-class\n",
    "\n",
    "    print(\"Evaluation Metrics:\")\n",
    "    print(f\"Accuracy:  {acc:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(true_labels, preds))\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(true_labels, preds, digits=4))\n",
    "\n",
    "    return acc, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_loader=DataLoader(train_dataset,batch_size=16,shuffle=True)\n",
    "val_loader=DataLoader(val_dataset,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from transformers import get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=1e-4,weight_decay=0.01)\n",
    "loss_fn = CrossEntropyLoss()\n",
    "\n",
    "# Move model to device (GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 20\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=200,\n",
    "    num_training_steps=len(train_loader) * num_epochs  # Number of steps per epoch * number of epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 1.1851\n",
      "Validation Loss: 1.1744, Accuracy: 0.3472, F1 Score: 0.1736\n",
      "Epoch 2/20, Loss: 1.1747\n",
      "Validation Loss: 1.1562, Accuracy: 0.3472, F1 Score: 0.1736\n",
      "Epoch 3/20, Loss: 1.1598\n",
      "Validation Loss: 1.1323, Accuracy: 0.3472, F1 Score: 0.1736\n",
      "Epoch 4/20, Loss: 1.1386\n",
      "Validation Loss: 1.1119, Accuracy: 0.3472, F1 Score: 0.1959\n",
      "Epoch 5/20, Loss: 1.1150\n",
      "Validation Loss: 1.1009, Accuracy: 0.3750, F1 Score: 0.2985\n",
      "Epoch 6/20, Loss: 1.0954\n",
      "Validation Loss: 1.0926, Accuracy: 0.4306, F1 Score: 0.3752\n",
      "Epoch 7/20, Loss: 1.0725\n",
      "Validation Loss: 1.0753, Accuracy: 0.4167, F1 Score: 0.4133\n",
      "Epoch 8/20, Loss: 1.0608\n",
      "Validation Loss: 1.0193, Accuracy: 0.5417, F1 Score: 0.5374\n",
      "Epoch 9/20, Loss: 1.0017\n",
      "Validation Loss: 0.9124, Accuracy: 0.5139, F1 Score: 0.5106\n",
      "Epoch 10/20, Loss: 0.8880\n",
      "Validation Loss: 0.8229, Accuracy: 0.5694, F1 Score: 0.5917\n",
      "Epoch 11/20, Loss: 0.8008\n",
      "Validation Loss: 0.8454, Accuracy: 0.5972, F1 Score: 0.5617\n",
      "Epoch 12/20, Loss: 0.7579\n",
      "Validation Loss: 0.7886, Accuracy: 0.5139, F1 Score: 0.4884\n",
      "Epoch 13/20, Loss: 0.7545\n",
      "Validation Loss: 0.7536, Accuracy: 0.5694, F1 Score: 0.5926\n",
      "Epoch 14/20, Loss: 0.7111\n",
      "Validation Loss: 0.8138, Accuracy: 0.5972, F1 Score: 0.6123\n",
      "Epoch 15/20, Loss: 0.7092\n",
      "Validation Loss: 0.7442, Accuracy: 0.5833, F1 Score: 0.6029\n",
      "Epoch 16/20, Loss: 0.6383\n",
      "Validation Loss: 0.7724, Accuracy: 0.6250, F1 Score: 0.6414\n",
      "Epoch 17/20, Loss: 0.6568\n",
      "Validation Loss: 0.7962, Accuracy: 0.5972, F1 Score: 0.6147\n",
      "Epoch 18/20, Loss: 0.6283\n",
      "Validation Loss: 0.7787, Accuracy: 0.6389, F1 Score: 0.6565\n",
      "Epoch 19/20, Loss: 0.6196\n",
      "Validation Loss: 0.7551, Accuracy: 0.6667, F1 Score: 0.6808\n",
      "Epoch 20/20, Loss: 0.6216\n",
      "Validation Loss: 0.7697, Accuracy: 0.6250, F1 Score: 0.6437\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()  # Update learning rate scheduler\n",
    "\n",
    "        # Keep track of the running loss\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # Evaluate on the validation set\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            correct_preds += (preds == labels).sum().item()\n",
    "            total_preds += labels.size(0)\n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "            all_labels.extend(labels.cpu().tolist())\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = (torch.tensor(all_preds) == torch.tensor(all_labels)).sum().item() / len(all_labels)\n",
    "    val_f1 = f1_score(all_labels, all_preds, average='macro')  # macro for multi-class balance\n",
    "\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}, Accuracy: {val_accuracy:.4f}, F1 Score: {val_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./saved_lora_model\\\\tokenizer_config.json',\n",
       " './saved_lora_model\\\\special_tokens_map.json',\n",
       " './saved_lora_model\\\\vocab.txt',\n",
       " './saved_lora_model\\\\added_tokens.json')"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save the weight/config/tokenizer\n",
    "output_dir = \"./saved_lora_model\"\n",
    "torch.save(model.state_dict(), f\"{output_dir}/pytorch_model.bin\")\n",
    "model.config.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TorchEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
